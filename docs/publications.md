## Publications

* IEEE Micro'22: <a href="https://ieeexplore.ieee.org/document/9933377">Special Issue on Artificial Intelligence at the Edge: RadioML meets FINN: Enabling Future RF Applications with FPGA Streaming Architectures</a>
* IEEE TECS'22: <a href="https://arxiv.org/abs/2201.11409">On the RTL Implementation of FINN Matrix Vector Unit</a>
* ACM TRETS: <a href="https://inaccel.com/wp-content/uploads/ACM_TRETS_DC_2020.pdf">Elastic-DF: Scaling Performance of DNN Inference in FPGA Clouds through Automatic Partitioning</a>
* FPGA'21: <a href="https://dl.acm.org/doi/abs/10.1145/3431920.3439283" target="_blank">S2N2: A Streaming Accelerator for Streaming Spiking Neural Networks</a> and [repository on GitHub](https://github.com/arkhodamoradi/s2n2)
* FPT'20: <a href="https://arxiv.org/pdf/2011.07317.pdf">Memory-Efficient Dataflow Inference for Deep CNNs on FPGA</a>
* IEEE ToC: <a href="https://ieeexplore.ieee.org/abstract/document/9187576/">Evaluation of Optimized CNNs on Heterogeneous Accelerators using a Novel Benchmarking Approach</a>
* FPL'20: <a href="https://arxiv.org/pdf/2004.03021.pdf">LogicNets: Co-Designed Neural Networks and Circuits for Extreme-Throughput Applications</a>
* FCCM'20: <a href="https://www.fccm.org/past/2020/proceedings/2020/pdfs/FCCM2020-65FOvhMqzyMYm99lfeVKyl/580300a238/580300a238.pdf">High-Throughput DNN Inference with LogicNets</a>
* GECCO'20: <a href="https://arxiv.org/pdf/2003.12449.pdf">Evolutionary Bin Packing for Memory-Efficient Dataflow Inference Acceleration on FPGA</a>
* FPGA'20: <a href="https://dl.acm.org/doi/abs/10.1145/3373087.3375348">Evaluation of Optimized CNNs on FPGA and non-FPGA based Accelerators using a Novel Benchmarking Approach</a>
* ACM JETC: <a href="https://arxiv.org/pdf/1909.05009">QuTiBench: Benchmarking neural networks on heterogeneous hardware</a>
* ACM TRETS: <a href="https://arxiv.org/pdf/1901.00370">Optimizing bit-serial matrix multiplication for reconfigurable computing</a>
* FPL'18: <a href="https://arxiv.org/pdf/1807.04093.pdf" target="_blank">FINN-L:Library Extensions and Design Trade-off Analysis for Variable Precision LSTM Networks on FPGAs</a>
* FPL'18: <a href="https://arxiv.org/pdf/1806.08862.pdf" target="_blank">BISMO: A Scalable Bit-Serial Matrix Multiplication Overlay for Reconfigurable Computing</a>
* FPL'18: <a href="http://kalman.mee.tcd.ie/fpl2018/content/pdfs/FPL2018-43iDzVTplcpussvbfIaaHz/XZmyRhWvHACdwHRVTCTVB/6jfImwD836ibhOELmms0Ut.pdf" target="_blank">Customizing Low-Precision Deep Neural Networks For FPGAs</a>
* ACM TRETS, Special Issue on Deep Learning: <a href="https://arxiv.org/abs/1809.04570" target="_blank">FINN-R: An End-to-End Deep-Learning Framework for Fast Exploration of Quantized Neural Networks</a>
* ARC'18: <a href="https://arxiv.org/pdf/1807.10577.pdf" target="_blank">Accuracy to Throughput Trade-Offs for Reduced Precision Neural Networks on Reconfigurable Logic</a>
* CVPR’18: <a href="https://arxiv.org/abs/1807.00301" target="_blank">SYQ: Learning Symmetric Quantization For Efﬁcient Deep Neural Networks</a>
* DATE'18: <a href="https://ieeexplore.ieee.org/abstract/document/8342121/" target="_blank">Inference of quantized neural networks on heterogeneous all-programmable devices</a>
* ICONIP’17: <a href="https://arxiv.org/abs/1709.06262" target="_blank">Compressing Low Precision Deep Neural Networks Using Sparsity-Induced Regularization in Ternary Networks</a>
* ICCD'17: <a href="https://ieeexplore.ieee.org/abstract/document/8119246/" target="_blank">Scaling Neural Network Performance through Customized Hardware Architectures on Reconfigurable Logic</a>
* PARMA-DITAM'17: <a href="https://arxiv.org/abs/1701.03400" target="_blank">Scaling Binarized Neural Networks on Reconfigurable Logic</a>
* FPGA'17: <a href="https://arxiv.org/abs/1612.07119" target="_blank">FINN: A Framework for Fast, Scalable Binarized Neural Network Inference</a>
* H2RC'16: <a href="https://h2rc.cse.sc.edu/2016/papers/paper_25.pdf" target="_blank">A C++ Library for Rapid Exploration of Binary Neural Networks on Reconfigurable Logic</a>

## External Publications and Projects Based on FINN

If you are using FINN in your work and would like to be listed here, please contact us! (jakoba.petri-koenig@amd.com)

* <a href="https://link.springer.com/chapter/10.1007/978-3-030-81645-2_9">Towards Real-Time Deep Learning-Based Network Intrusion Detection on FPGA (KU Leuven)<\a>
* <a href="https://arxiv.org/abs/2112.00170">SAMO: Optimised Mapping of Convolutional Neural Networks to Streaming Architectures (Imperial College London)</a>
* <a href="https://ieeexplore.ieee.org/document/9245522" target="_blank">Spatio-Temporal Optimization of Deep Neural Networks for Reconfigurable FPGA SoCs (Scoula Superiore Sant'Anna)</a>
* <a href="https://coefs.uncc.edu/htabkhiv/teaching/hardware-software-co-design-real-time-ai/" target="_blank">Hardware-Software Co-Design Real-time AI (UNC Charlotte)</a>
* <a href="https://ieeexplore.ieee.org/abstract/document/8442108" target="_blank">BinaryEye: A 20 kfps Streaming Camera System on FPGA with Real-Time On-Device Image Recognition Using Binary Neural Networks</a>
* <a href="https://qiita.com/ykshr/items/08147098516a45203761" target="_blank">Cucumber sorting with FINN (in Japanese)</a>
* <a href="https://github.com/mohaghasemzadeh/ReBNet" target="_blank">ReBNet: Residual Binarized Neural Network, FCCM'18 best paper</a>
