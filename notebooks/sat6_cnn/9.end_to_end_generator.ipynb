{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1badb523-c6f0-4e99-aaa5-4ebe9f10df86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnns_classes import t1_quantizedCNN, t2_quantizedCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0c2b2db-5916-4a54-8889-48ea4e2b716c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc65c330290>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://www.kaggle.com/code/vmarkin/advatt\n",
    "# carregar as bibliotecas básicas necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# gerar os gráficos logo abaixo dos comandos de plot\n",
    "%matplotlib inline\n",
    "torch.manual_seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d81471c7-2d16-4eba-b639-616485bad27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_qtdy = 324000\n",
    "test_qtdy = 81000\n",
    "batch_size = 512\n",
    "npy_data_size = 1000 #for simulation\n",
    "\n",
    "train_data_path = './dataset/X_train_sat6.csv'\n",
    "train_label_path = './dataset/y_train_sat6.csv'\n",
    "test_data_path = './dataset/X_test_sat6.csv'\n",
    "test_label_path = './dataset/y_test_sat6.csv'\n",
    "\n",
    "t1_quantizations=[2,4,8]\n",
    "t2_quantizations=[2,4,8]\n",
    "\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "380c6017-c297-4a4b-a4ed-5f4ee17f5045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_read(data_path, nrows):\n",
    "    data=pd.read_csv(data_path, header=None, nrows=nrows, dtype=np.uint8)\n",
    "    data=data.values ## converting the data into numpy array\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8a60b4f-80ad-4702-adf4-9205731ef663",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatImgDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = T.ToTensor()\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.transform(self.X[index])\n",
    "        y = torch.FloatTensor(self.y[index])\n",
    "        return {'x':x, 'y':y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59011b8f-e610-4a7e-bf51-33f5c4749f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:(324000, 3136)\n",
      "Train data label shape:(324000, 6)\n",
      "Test data shape:(81000, 3136)\n",
      "Test data label shape:(81000, 6)\n"
     ]
    }
   ],
   "source": [
    "train_data=data_read(train_data_path, nrows=train_qtdy)\n",
    "print(\"Train data shape:\" + str(train_data.shape))\n",
    "\n",
    "##Read training data labels\n",
    "train_data_label=data_read(train_label_path,nrows=train_qtdy)\n",
    "print(\"Train data label shape:\" + str(train_data_label.shape))\n",
    "\n",
    "##Read test data\n",
    "test_data=data_read(test_data_path, nrows=test_qtdy)\n",
    "print(\"Test data shape:\" + str(test_data.shape))\n",
    "\n",
    "##Read test data labels\n",
    "test_data_label=data_read(test_label_path,nrows=test_qtdy)\n",
    "print(\"Test data label shape:\" + str(test_data_label.shape))\n",
    "\n",
    "train_data_reshaped = train_data.reshape(train_qtdy,28,28,4)\n",
    "test_data_reshaped = test_data.reshape(test_qtdy,28,28,4) \n",
    "\n",
    "final_train_data = np.zeros((train_qtdy, 32, 32, 4),dtype=np.float32)\n",
    "final_train_data[:, :28, :28, :] = train_data_reshaped;\n",
    "\n",
    "final_test_data = np.zeros((test_qtdy, 32, 32, 4),dtype=np.float32)\n",
    "final_test_data[:, :28, :28, :] = test_data_reshaped;\n",
    "\n",
    "output_tensor = []\n",
    "\n",
    "for label in test_data_label:\n",
    "    output_tensor.append(label.argmax())\n",
    "\n",
    "input_tensor = torch.from_numpy(final_test_data[:npy_data_size])\n",
    "output_tensor = torch.Tensor(output_tensor[:npy_data_size])\n",
    "\n",
    "np.save(\"input.npy\", input_tensor)\n",
    "np.save(\"expected_output.npy\", output_tensor)\n",
    "\n",
    "dataset_train = SatImgDataset(final_train_data, train_data_label)\n",
    "dataset_test = SatImgDataset(final_test_data, test_data_label)\n",
    "\n",
    "loader_train = DataLoader(dataset_train, batch_size, shuffle=True)\n",
    "loader_test = DataLoader(dataset_test, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9da9aa18-a40b-4225-adf7-ccd18d408712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_output_filename (topology,quant):\n",
    "    return f\"./pytorch_models/sat6-cnn-t{topology}w{quant}.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a622b1a-3669-48ec-a12c-c0e60e0cb06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs,lr,topology,topology_class,quant):\n",
    "    print(f\"training t{topology}w{quant}\")\n",
    "    model = topology_class(bit_quantization=quant)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    epochs = epochs\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    i=0\n",
    "    for e in range(epochs):\n",
    "        if i % 5 == 0:\n",
    "            print(f\"epoch ({i})\") \n",
    "        for batch in tqdm(loader_train):\n",
    "            pred = model(batch['x'].to(device))\n",
    "            loss = criterion(pred, batch['y'].to(device))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        i+=1\n",
    "\n",
    "    print(\"saving the pytorch model...\")    \n",
    "    torch.save(model.state_dict(), get_model_output_filename(topology=topology,quant=quant))\n",
    "    print(\"finishing training\")\n",
    "    return get_model_output_filename(topology=topology,quant=quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "972ce846-5b23-4e26-8bce-02c05cc9d246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(topology,topology_class,model_filename,quant):\n",
    "    print(f\"testing t{topology}w{quant}\")\n",
    "    model = topology_class(bit_quantization=quant)\n",
    "    model.load_state_dict(torch.load(model_filename))\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        i=0\n",
    "        for batch in loader_test:\n",
    "            pred = model(batch['x'].to(device))\n",
    "            predicted = torch.max(pred, 1)[1]\n",
    "            real_class = torch.max(batch['y'].to(device), 1)[1]\n",
    "            correct += (predicted == real_class).sum()    \n",
    "    accuracy = correct.item()/len(dataset_test)*100\n",
    "    print(f\"accuracy of this model: {accuracy}% ({len(dataset_test)} test cases)\")\n",
    "    print(f\"finishing testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e2d4520-288e-47c0-8cb7-ceed8a0f48ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(topology_class,topology,quant):\n",
    "    print(f\"starting to generate pytorch model t{topology}w{quant}\")\n",
    "    model_filename = train_model(epochs=30,topology=topology,lr=3e-4,topology_class=topology_class,quant=quant)\n",
    "    test_model(topology=topology,topology_class=topology_class,model_filename=model_filename,quant=quant)\n",
    "    print(f\"finishing model generate\")\n",
    "    print(f\"------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aaaf314-bb2f-40b0-a665-18894163d81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting to generate pytorch model t1w2\n",
      "training t1w2\n",
      "epoch (0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [01:08<00:00,  9.22it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:54<00:00, 11.55it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:57<00:00, 10.93it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:55<00:00, 11.47it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:54<00:00, 11.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:55<00:00, 11.43it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:57<00:00, 11.06it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:53<00:00, 11.78it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:53<00:00, 11.86it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:56<00:00, 11.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:57<00:00, 11.08it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:58<00:00, 10.89it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:57<00:00, 10.98it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [01:09<00:00,  9.05it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [01:07<00:00,  9.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [01:00<00:00, 10.51it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.15it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.11it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.45it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.54it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.14it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.34it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.47it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.21it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.34it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.44it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.44it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the pytorch model...\n",
      "finishing training\n",
      "testing t1w2\n",
      "accuracy of this model: 4.5851851851851855% (81000 test cases)\n",
      "finishing testing\n",
      "finishing model generate\n",
      "------------------------\n",
      "starting to generate pytorch model t1w4\n",
      "training t1w4\n",
      "epoch (0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:50<00:00, 12.59it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.26it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.58it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.43it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:43<00:00, 14.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.09it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.30it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:43<00:00, 14.59it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.27it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:42<00:00, 14.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.11it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:42<00:00, 15.04it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:42<00:00, 15.01it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.21it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.42it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.28it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.51it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.08it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.60it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.36it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:42<00:00, 15.00it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.53it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.12it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.19it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.42it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.41it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the pytorch model...\n",
      "finishing training\n",
      "testing t1w4\n",
      "accuracy of this model: 86.68148148148148% (81000 test cases)\n",
      "finishing testing\n",
      "finishing model generate\n",
      "------------------------\n",
      "starting to generate pytorch model t1w8\n",
      "training t1w8\n",
      "epoch (0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:51<00:00, 12.35it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:42<00:00, 14.98it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.43it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.36it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.48it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.50it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:42<00:00, 14.96it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.55it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.64it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.20it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.53it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.52it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.56it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.64it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:42<00:00, 15.05it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.54it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:43<00:00, 14.52it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [01:00<00:00, 10.39it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:45<00:00, 13.99it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.77it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:39<00:00, 15.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.77it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.44it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.16it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.69it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:40<00:00, 15.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the pytorch model...\n",
      "finishing training\n",
      "testing t1w8\n",
      "accuracy of this model: 98.58148148148148% (81000 test cases)\n",
      "finishing testing\n",
      "finishing model generate\n",
      "------------------------\n",
      "starting to generate pytorch model t2w2\n",
      "training t2w2\n",
      "epoch (0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:37<00:00, 16.90it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:30<00:00, 20.75it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:32<00:00, 19.40it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:35<00:00, 17.98it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:34<00:00, 18.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:32<00:00, 19.45it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:30<00:00, 20.45it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:31<00:00, 20.33it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:37<00:00, 16.94it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:34<00:00, 18.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:33<00:00, 18.66it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:34<00:00, 18.48it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:32<00:00, 19.23it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:30<00:00, 20.43it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:31<00:00, 20.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:30<00:00, 20.58it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:31<00:00, 20.40it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:31<00:00, 20.39it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:31<00:00, 20.02it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:32<00:00, 19.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:32<00:00, 19.62it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:31<00:00, 20.21it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:32<00:00, 19.60it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:33<00:00, 18.85it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:32<00:00, 19.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:34<00:00, 18.42it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:34<00:00, 18.55it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:34<00:00, 18.52it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:31<00:00, 19.98it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:34<00:00, 18.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the pytorch model...\n",
      "finishing training\n",
      "testing t2w2\n",
      "accuracy of this model: 89.18518518518519% (81000 test cases)\n",
      "finishing testing\n",
      "finishing model generate\n",
      "------------------------\n",
      "starting to generate pytorch model t2w4\n",
      "training t2w4\n",
      "epoch (0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:38<00:00, 16.46it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:30<00:00, 20.50it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:30<00:00, 20.59it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:30<00:00, 20.43it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:31<00:00, 20.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:30<00:00, 20.61it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:30<00:00, 20.63it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:30<00:00, 20.51it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:30<00:00, 20.55it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:31<00:00, 20.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:35<00:00, 17.70it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:38<00:00, 16.56it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:33<00:00, 18.99it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:34<00:00, 18.24it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:36<00:00, 17.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:34<00:00, 18.19it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:36<00:00, 17.41it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:38<00:00, 16.42it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:36<00:00, 17.32it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:33<00:00, 18.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:35<00:00, 17.63it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:31<00:00, 20.24it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:31<00:00, 20.04it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:31<00:00, 20.23it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:34<00:00, 18.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:38<00:00, 16.32it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:37<00:00, 16.77it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:37<00:00, 16.93it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:52<00:00, 12.15it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:35<00:00, 17.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the pytorch model...\n",
      "finishing training\n",
      "testing t2w4\n",
      "accuracy of this model: 96.69876543209877% (81000 test cases)\n",
      "finishing testing\n",
      "finishing model generate\n",
      "------------------------\n",
      "starting to generate pytorch model t2w8\n",
      "training t2w8\n",
      "epoch (0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:45<00:00, 13.88it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:33<00:00, 18.83it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:36<00:00, 17.12it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:36<00:00, 17.12it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:36<00:00, 17.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:37<00:00, 16.83it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:37<00:00, 17.01it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:36<00:00, 17.18it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:32<00:00, 19.32it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:31<00:00, 20.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:30<00:00, 20.59it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:32<00:00, 19.71it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:38<00:00, 16.53it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:36<00:00, 17.55it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:34<00:00, 18.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:31<00:00, 20.04it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:31<00:00, 20.36it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:31<00:00, 20.28it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:33<00:00, 19.13it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:36<00:00, 17.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:39<00:00, 16.01it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:35<00:00, 17.66it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:32<00:00, 19.51it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:31<00:00, 20.13it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:31<00:00, 20.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:35<00:00, 18.07it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:31<00:00, 19.91it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:31<00:00, 20.08it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:34<00:00, 18.22it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:36<00:00, 17.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving the pytorch model...\n",
      "finishing training\n",
      "testing t2w8\n",
      "accuracy of this model: 98.79506172839505% (81000 test cases)\n",
      "finishing testing\n",
      "finishing model generate\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "for quant in t1_quantizations:\n",
    "    make_model(topology_class=t1_quantizedCNN,topology=1,quant=quant)\n",
    "\n",
    "for quant in t2_quantizations:\n",
    "    make_model(topology_class=t2_quantizedCNN,topology=2,quant=quant)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a75b6ff-15f8-4b3b-85b7-b04de34feafd",
   "metadata": {},
   "source": [
    "Hardware generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53d03afd-e47e-47ba-8c4a-c533c960bf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn.util.basic import make_build_dir\n",
    "from finn.util.visualization import showInNetron\n",
    "import os\n",
    "    \n",
    "build_dir = os.environ[\"FINN_BUILD_DIR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b304e4da-96d8-4bb1-82ae-bc1c1521d662",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.core.datatype import DataType\n",
    "import torch\n",
    "import onnx\n",
    "from finn.util.test import get_test_model_trained\n",
    "from brevitas.export import export_qonnx\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.general import GiveReadableTensorNames, GiveUniqueNodeNames, RemoveStaticGraphInputs\n",
    "from qonnx.transformation.insert_topk import InsertTopK\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "from finn.transformation.streamline import Streamline\n",
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from qonnx.transformation.bipolar_to_xnor import ConvertBipolarMatMulToXnorPopcount\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC, MoveScalarLinearPastInvariants\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.general import RemoveUnusedTensors\n",
    "import finn.transformation.fpgadataflow.convert_to_hls_layers as to_hls\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import (\n",
    "    CreateDataflowPartition,\n",
    ")\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "from qonnx.custom_op.registry import getCustomOp\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "import finn.builder.build_dataflow as build\n",
    "import finn.builder.build_dataflow_config as build_cfg\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ab93d69a-955b-41ca-8926-abefd65cecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onnx_output_filename (topology,quant):\n",
    "    return f\"./hardware_onnxs/sat6-cnn-t{topology}w{quant}.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c55a919-a517-4c14-8a9f-fee173804e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_onnx(cnv,quant,topology):\n",
    "    cnv.load_state_dict(torch.load(get_model_output_filename(topology=topology,quant=quant)))\n",
    "    onnx_output_filename = get_onnx_output_filename(topology=topology,quant=quant)\n",
    "    \n",
    "    export_onnx_path = build_dir + f\"/end2end_cnv_t{topology}w{quant}_export.onnx\"\n",
    "    #tidy up\n",
    "    export_qonnx(cnv, torch.randn(1, 4, 32, 32), export_onnx_path)    \n",
    "    qonnx_cleanup(export_onnx_path, out_file=export_onnx_path)\n",
    "    model = ModelWrapper(export_onnx_path)\n",
    "    model = model.transform(ConvertQONNXtoFINN())\n",
    "    model = model.transform(InferShapes())\n",
    "    model = model.transform(FoldConstants())\n",
    "    model = model.transform(GiveUniqueNodeNames())\n",
    "    model = model.transform(GiveReadableTensorNames())\n",
    "    model = model.transform(RemoveStaticGraphInputs())\n",
    "\n",
    "    #preprocessing\n",
    "    global_inp_name = model.graph.input[0].name\n",
    "    model.set_tensor_datatype(global_inp_name, DataType[\"UINT8\"])\n",
    "\n",
    "    # postprocessing: insert Top-1 node at the end\n",
    "    model = model.transform(InsertTopK(k=1))\n",
    "    # tidy-up again\n",
    "    model = model.transform(InferShapes())\n",
    "    model = model.transform(FoldConstants())\n",
    "    model = model.transform(GiveUniqueNodeNames())\n",
    "    model = model.transform(GiveReadableTensorNames())\n",
    "    model = model.transform(InferDataTypes())\n",
    "    model = model.transform(RemoveStaticGraphInputs())\n",
    "\n",
    "    model = model.transform(MoveScalarLinearPastInvariants())\n",
    "    model = model.transform(Streamline())\n",
    "    model = model.transform(LowerConvsToMatMul())\n",
    "    model = model.transform(MakeMaxPoolNHWC())\n",
    "    model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "    model = model.transform(ConvertBipolarMatMulToXnorPopcount())\n",
    "    model = model.transform(Streamline())\n",
    "    # absorb final add-mul nodes into TopK\n",
    "    model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "    model = model.transform(InferDataLayouts())\n",
    "    model = model.transform(RemoveUnusedTensors())\n",
    "\n",
    "    # choose the memory mode for the MVTU units, decoupled or const\n",
    "    mem_mode = \"const\"    \n",
    "    model = model.transform(to_hls.InferBinaryMatrixVectorActivation(mem_mode))\n",
    "    model = model.transform(to_hls.InferQuantizedMatrixVectorActivation(mem_mode))\n",
    "    # TopK to LabelSelect\n",
    "    model = model.transform(to_hls.InferLabelSelectLayer())\n",
    "    # input quantization (if any) to standalone thresholding\n",
    "    model = model.transform(to_hls.InferThresholdingLayer())\n",
    "    model = model.transform(to_hls.InferConvInpGen())\n",
    "    model = model.transform(to_hls.InferStreamingMaxPool())\n",
    "    # get rid of Reshape(-1, 1) operation between hlslib nodes\n",
    "    model = model.transform(RemoveCNVtoFCFlatten())\n",
    "    # get rid of Tranpose -> Tranpose identity seq\n",
    "    model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "    # infer tensor data layouts\n",
    "    model = model.transform(InferDataLayouts())\n",
    "    parent_model = model.transform(CreateDataflowPartition())\n",
    "    parent_model.save(build_dir + f\"/end2end_cnv_t{topology}w{quant}_dataflow_parent.onnx\")\n",
    "    sdp_node = parent_model.get_nodes_by_op_type(\"StreamingDataflowPartition\")[0]\n",
    "    sdp_node = getCustomOp(sdp_node)\n",
    "    dataflow_model_filename = sdp_node.get_nodeattr(\"model\")\n",
    "    # save the dataflow partition with a different name for easier access\n",
    "    dataflow_model = ModelWrapper(dataflow_model_filename)\n",
    "    dataflow_model.save(onnx_output_filename)\n",
    "    return onnx_output_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "72e42219-6266-435f-ba07-1c08ddf2d233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_hardware(topology,quant,target_fps):\n",
    "    model_file = get_onnx_output_filename(topology,quant)\n",
    "    \n",
    "    estimates_output_dir = f\"./builds/build_t{topology}w{quant}\"\n",
    "    \n",
    "    #Delete previous run results if exist\n",
    "    if os.path.exists(estimates_output_dir):\n",
    "        shutil.rmtree(estimates_output_dir)\n",
    "        print(\"Previous run results deleted!\")\n",
    "    \n",
    "    cfg_estimates = build.DataflowBuildConfig(\n",
    "        output_dir          = estimates_output_dir,\n",
    "        mvau_wwidth_max     = 1000000, #tinha usado 80\n",
    "        target_fps          = target_fps, #tinha usado 100\n",
    "        synth_clk_period_ns = 10.0,\n",
    "        rtlsim_batch_size   = npy_data_size,\n",
    "        folding_config_file = \"/home/artti/Desktop/finn/notebooks/sat6_cnn/folding.json\",\n",
    "        verify_input_npy    = \"input.npy\",\n",
    "        stitched_ip_gen_dcp = True,\n",
    "        verify_expected_output_npy = \"expected_output.npy\",\n",
    "        # verify_save_rtlsim_waveforms = True,\n",
    "        board = \"Pynq-Z1\",\n",
    "        shell_flow_type = build_cfg.ShellFlowType.VIVADO_ZYNQ,\n",
    "        default_mem_mode = build_cfg.ComputeEngineMemMode.CONST,\n",
    "        generate_outputs=[\n",
    "            build_cfg.DataflowOutputType.ESTIMATE_REPORTS,\n",
    "            build_cfg.DataflowOutputType.STITCHED_IP,\n",
    "            build_cfg.DataflowOutputType.RTLSIM_PERFORMANCE,\n",
    "            build_cfg.DataflowOutputType.OOC_SYNTH,\n",
    "            build_cfg.DataflowOutputType.BITFILE,\n",
    "            build_cfg.DataflowOutputType.PYNQ_DRIVER,\n",
    "            build_cfg.DataflowOutputType.DEPLOYMENT_PACKAGE,\n",
    "        ]\n",
    "        # ,\n",
    "        # verify_steps=[\n",
    "        #     build_cfg.VerificationStepType.STITCHED_IP_RTLSIM,\n",
    "        # ]\n",
    "    )    \n",
    "    \n",
    "    build.build_dataflow_cfg(model_file, cfg_estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7dc31b45-6f80-445a-9c09-4aebeb59ad15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_hardware(topology,topology_class,quant):\n",
    "    cnv = topology_class(bit_quantization=quant)\n",
    "    onnx_filename = make_onnx(cnv=cnv,quant=quant,topology=topology)\n",
    "    generate_hardware(target_fps=1000,quant=quant,topology=topology)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9406e3d7-15cf-4e72-88ec-a2e0f7397e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/artti/Desktop/finn/deps/qonnx/src/qonnx/transformation/infer_data_layouts.py:119: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous run results deleted!\n",
      "Building dataflow accelerator from ./hardware_onnxs/sat6-cnn-t1w2.onnx\n",
      "Intermediate outputs will be generated in /tmp/finn_dev_artti\n",
      "Final outputs will be generated in ./builds/build_t1w2\n",
      "Build log is at ./builds/build_t1w2/build_dataflow.log\n",
      "Running step: step_qonnx_to_finn [1/18]\n",
      "Running step: step_tidy_up [2/18]\n",
      "Running step: step_streamline [3/18]\n",
      "Running step: step_convert_to_hls [4/18]\n",
      "Running step: step_create_dataflow_partition [5/18]\n",
      "Running step: step_target_fps_parallelization [6/18]\n",
      "Running step: step_apply_folding_config [7/18]\n",
      "Running step: step_minimize_bit_width [8/18]\n",
      "Running step: step_generate_estimate_reports [9/18]\n",
      "Running step: step_hls_codegen [10/18]\n",
      "Running step: step_hls_ipgen [11/18]\n",
      "Running step: step_set_fifo_depths [12/18]\n",
      "Running step: step_create_stitched_ip [13/18]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/artti/Desktop/finn/src/finn/builder/build_dataflow.py\", line 158, in build_dataflow_cfg\n",
      "    model = transform_step(model, cfg)\n",
      "  File \"/home/artti/Desktop/finn/src/finn/builder/build_dataflow_steps.py\", line 643, in step_measure_rtlsim_performance\n",
      "    DataflowOutputType.STITCHED_IP in cfg.generate_outputs\n",
      "AssertionError: rtlsim_perf needs stitched IP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step: step_measure_rtlsim_performance [14/18]\n",
      "> \u001b[0;32m/home/artti/Desktop/finn/src/finn/builder/build_dataflow_steps.py\u001b[0m(643)\u001b[0;36mstep_measure_rtlsim_performance\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    641 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0mDataflowOutputType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTLSIM_PERFORMANCE\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_outputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    642 \u001b[0;31m        assert (\n",
      "\u001b[0m\u001b[0;32m--> 643 \u001b[0;31m            \u001b[0mDataflowOutputType\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTITCHED_IP\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    644 \u001b[0;31m        ), \"rtlsim_perf needs stitched IP\"\n",
      "\u001b[0m\u001b[0;32m    645 \u001b[0;31m        \u001b[0mreport_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/report\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "--KeyboardInterrupt--\n",
      "\n",
      "KeyboardInterrupt: Interrupted by user\n",
      "Build failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for quant in t1_quantizations:\n",
    "    build_hardware(1,t1_quantizedCNN,quant)\n",
    "\n",
    "for quant in t2_quantizations:\n",
    "    build_hardware(2,t2_quantizedCNN,quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c63027-0799-487a-9ccd-2e0918935f25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
