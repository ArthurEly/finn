{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/code/vmarkin/advatt\n",
    "# carregar as bibliotecas básicas necessárias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# gerar os gráficos logo abaixo dos comandos de plot\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path = '../dataset/X_train_sat6.csv'\n",
    "train_label_path = '../dataset/y_train_sat6.csv'\n",
    "test_data_path = '../dataset/X_test_sat6.csv'\n",
    "test_label_path = '../dataset/y_test_sat6.csv'\n",
    "# train_qtdy = 10000\n",
    "# test_qtdy = 2048     \n",
    "train_qtdy = 324000\n",
    "test_qtdy = 81000     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_read(data_path, nrows):\n",
    "    data=pd.read_csv(data_path, header=None, nrows=nrows, dtype=np.uint8)\n",
    "    data=data.values ## converting the data into numpy array\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:(324000, 3136)\n",
      "Train data label shape:(324000, 6)\n",
      "Test data shape:(81000, 3136)\n",
      "Test data label shape:(81000, 6)\n"
     ]
    }
   ],
   "source": [
    "train_data=data_read(train_data_path, nrows=train_qtdy)\n",
    "print(\"Train data shape:\" + str(train_data.shape))\n",
    "\n",
    "##Read training data labels\n",
    "train_data_label=data_read(train_label_path,nrows=train_qtdy)\n",
    "print(\"Train data label shape:\" + str(train_data_label.shape))\n",
    "\n",
    "##Read test data\n",
    "test_data=data_read(test_data_path, nrows=test_qtdy)\n",
    "print(\"Test data shape:\" + str(test_data.shape))\n",
    "\n",
    "##Read test data labels\n",
    "test_data_label=data_read(test_label_path,nrows=test_qtdy)\n",
    "print(\"Test data label shape:\" + str(test_data_label.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3136,)\n",
      "[[[116 119 118]\n",
      "  [108 113 118]\n",
      "  [ 67  60  59]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " [[122 128 119]\n",
      "  [113 121 114]\n",
      "  [ 64  63  46]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " [[105 105  93]\n",
      "  [110 117 106]\n",
      "  [ 95 101  90]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " [[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " [[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]]\n",
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "example = train_data[0]\n",
    "print(example.shape)\n",
    "reshaped_ex = example.reshape((28,28,4))[:,:,:3] #convert to rgb \n",
    "\n",
    "ex = np.zeros((32, 32, 3),dtype=np.int32)\n",
    "ex[:28, :28, :] = reshaped_ex\n",
    "print(ex)\n",
    "print(ex.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fe9cf6ae3b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_label = train_data_label[0]\n",
    "ex_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fea46abeeb0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "torch.manual_seed(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SatImgDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = T.ToTensor()\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.transform(self.X[index])\n",
    "        y = torch.FloatTensor(self.y[index])\n",
    "        return {'x':x, 'y':y}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_reshaped = train_data.reshape(train_qtdy,28,28,4)\n",
    "test_data_reshaped = test_data.reshape(test_qtdy,28,28,4) \n",
    "\n",
    "final_train_data = np.zeros((train_qtdy, 32, 32, 4),dtype=np.float32)\n",
    "final_train_data[:, :28, :28, :] = train_data_reshaped;\n",
    "\n",
    "final_test_data = np.zeros((test_qtdy, 32, 32, 4),dtype=np.float32)\n",
    "final_test_data[:, :28, :28, :] = test_data_reshaped;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = SatImgDataset(final_train_data, train_data_label)\n",
    "dataset_test = SatImgDataset(final_test_data, test_data_label)\n",
    "\n",
    "loader_train = DataLoader(dataset_train, 512, shuffle=True)\n",
    "loader_test = DataLoader(dataset_test, 512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (C) 2023, Advanced Micro Devices, Inc. All rights reserved.\n",
    "# SPDX-License-Identifier: BSD-3-Clause\n",
    "\n",
    "from dependencies import value\n",
    "\n",
    "from brevitas.core.bit_width import BitWidthImplType\n",
    "from brevitas.core.quant import QuantType\n",
    "from brevitas.core.restrict_val import FloatToIntImplType\n",
    "from brevitas.core.restrict_val import RestrictValueType\n",
    "from brevitas.core.scaling import ScalingImplType\n",
    "from brevitas.core.zero_point import ZeroZeroPoint\n",
    "from brevitas.inject import ExtendedInjector\n",
    "from brevitas.quant.solver import ActQuantSolver\n",
    "from brevitas.quant.solver import WeightQuantSolver\n",
    "from brevitas.quant import Uint8ActPerTensorFloat\n",
    "\n",
    "class CommonQuant(ExtendedInjector):\n",
    "    bit_width_impl_type = BitWidthImplType.CONST\n",
    "    scaling_impl_type = ScalingImplType.CONST\n",
    "    restrict_scaling_type = RestrictValueType.FP\n",
    "    zero_point_impl = ZeroZeroPoint\n",
    "    float_to_int_impl_type = FloatToIntImplType.ROUND\n",
    "    scaling_per_output_channel = False\n",
    "    narrow_range = True\n",
    "    signed = True\n",
    "\n",
    "    @value\n",
    "    def quant_type(bit_width):\n",
    "        if bit_width is None:\n",
    "            return QuantType.FP\n",
    "        elif bit_width == 1:\n",
    "            return QuantType.BINARY\n",
    "        else:\n",
    "            return QuantType.INT\n",
    "\n",
    "\n",
    "class CommonWeightQuant(CommonQuant, WeightQuantSolver):\n",
    "    scaling_const = 1.0\n",
    "\n",
    "\n",
    "class CommonUintActQuant(Uint8ActPerTensorFloat):\n",
    "    \"\"\"\n",
    "    Common unsigned act quantizer with bit-width set to None so that it's forced to be specified by\n",
    "    each layer.\n",
    "    \"\"\"\n",
    "    scaling_min_val = 2e-16\n",
    "    bit_width = None\n",
    "    restrict_scaling_type = RestrictValueType.LOG_FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import brevitas.nn as qnn\n",
    "from brevitas.quant.scaled_int import Int8ActPerTensorFloat\n",
    "\n",
    "bit_quantization = 8\n",
    "\n",
    "class QuantizedCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QuantizedCNN, self).__init__()\n",
    "        self.conv1 = qnn.QuantConv2d(\n",
    "            4, \n",
    "            20, \n",
    "            kernel_size=3, stride=2, padding=1, \n",
    "            bias = False,\n",
    "            weight_bit_width=bit_quantization, \n",
    "            weight_quant=CommonWeightQuant, \n",
    "        )\n",
    "        self.relu1 = qnn.QuantReLU(\n",
    "            act_quant=CommonUintActQuant,\n",
    "            bit_width=bit_quantization,\n",
    "            return_quant_tensor=True\n",
    "        )\n",
    "        \n",
    "        self.conv2 = qnn.QuantConv2d(\n",
    "            20, \n",
    "            8, \n",
    "            kernel_size=1, stride=1,\n",
    "            bias = False,\n",
    "            weight_bit_width=bit_quantization, \n",
    "            weight_quant=CommonWeightQuant, \n",
    "        )\n",
    "        self.relu2 = qnn.QuantReLU(\n",
    "            act_quant=CommonUintActQuant,\n",
    "            bit_width=bit_quantization,\n",
    "            return_quant_tensor=True\n",
    "        )\n",
    "        \n",
    "        self.fc1 = qnn.QuantLinear(\n",
    "            8*16*16, \n",
    "            6, \n",
    "            bias = False,\n",
    "            weight_bit_width=bit_quantization, \n",
    "            weight_quant=CommonWeightQuant, \n",
    "        )\n",
    "\n",
    "        # for m in self.modules():\n",
    "        #     if isinstance(m, qnn.QuantConv2d) or isinstance(m, qnn.QuantLinear):\n",
    "        #         nn.init.uniform_(m.weight.data, -1, 1)\n",
    "        #         if m.bias is not None:\n",
    "        #             nn.init.zeros_(m.bias.data)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = 2.0 * x - torch.tensor([1.0], device=x.device)\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = self.fc1(x)      \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:52<00:00, 12.00it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.26it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.14it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.19it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.23it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.18it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.33it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.33it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.24it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.30it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.14it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.27it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (15)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.31it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.26it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.39it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.28it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.30it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.23it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.27it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.18it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:44<00:00, 14.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.10it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:42<00:00, 14.94it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.17it/s]\n",
      "100%|█████████████████████████████████████████| 633/633 [00:41<00:00, 15.13it/s]\n",
      " 84%|██████████████████████████████████▍      | 532/633 [00:35<00:06, 15.27it/s]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = QuantizedCNN()\n",
    "device = torch.device('cpu')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "epochs = 30\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "model.train()\n",
    "i=0\n",
    "for e in range(epochs):\n",
    "    if i % 5 == 0:\n",
    "        print(f\"epoch ({i})\") \n",
    "    for batch in tqdm(loader_train):\n",
    "        pred = model(batch['x'].to(device))\n",
    "        loss = criterion(pred, batch['y'].to(device))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    i=0\n",
    "    for batch in loader_test:\n",
    "        pred = model(batch['x'].to(device))\n",
    "        predicted = torch.max(pred, 1)[1]\n",
    "        real_class = torch.max(batch['y'].to(device), 1)[1]\n",
    "        correct += (predicted == real_class).sum()\n",
    "        if (i % 100 == 0):\n",
    "            print(predicted)\n",
    "            print(real_class)\n",
    "        i += 1\n",
    "\n",
    "print(f\"certos: {correct.item()}!!!\")\n",
    "print(f\"precisão: {correct.item()/len(dataset_test)*100}%!!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_one_image(model, img_data, y):\n",
    "    with torch.no_grad():\n",
    "        pred = model(T.ToTensor()(img_data).unsqueeze(0).to(device))\n",
    "    true_label = y.argmax()\n",
    "    pred_label = pred[0].argmax()\n",
    "    print(pred)\n",
    "    plt.imshow(img_data.astype(int))\n",
    "    print(\"True class: {}, predicted class: {}\".format(true_label, pred_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_params = {'epsilon':0.02}\n",
    "\n",
    "image_index = 0\n",
    "\n",
    "img_data = test_data[image_index].reshape((28,28,4))\n",
    "\n",
    "ex_img = np.zeros((32, 32, 4),dtype=np.float32)\n",
    "ex_img[:28, :28, :] = img_data\n",
    "\n",
    "labels = torch.FloatTensor(test_data_label[image_index]).unsqueeze(0)\n",
    "predict_one_image(model, ex_img, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#salvar e carregar o modelo de NN\n",
    "torch.save(model.state_dict(), \"cnn-sat6-w8.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = QuantizedCNN()\n",
    "new_model.load_state_dict(torch.load(\"cnn-sat6-w8.pt\"))\n",
    "predict_one_image(new_model, ex_img, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
